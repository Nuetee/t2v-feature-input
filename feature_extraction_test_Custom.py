import torch
from PIL import Image
from custom_clip_vision_encoder import CustomCLIPVisionEncoder  # âœ… ì§ì ‘ ë§Œë“  Vision Tower ì„í¬íŠ¸

# âœ… 1ï¸âƒ£ CustomCLIPVisionEncoder ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
vision_tower = CustomCLIPVisionEncoder(model_name="openai/clip-vit-large-patch14-336", 
                                       select_layer=-2, select_feature="patch").to(device)

# âœ… 2ï¸âƒ£ Image Processor ê°€ì ¸ì˜¤ê¸°
image_processor = vision_tower.image_processor  # âœ… CLIP Image Processor ê°€ì ¸ì˜¤ê¸°

# âœ… 3ï¸âƒ£ `expand2square()` í•¨ìˆ˜ ì¶”ê°€ (load_images()ì™€ ë™ì¼í•œ ë°©ì‹)
def expand2square(pil_img, background_color):
    width, height = pil_img.size
    if width == height:
        return pil_img
    elif width > height:
        result = Image.new(pil_img.mode, (width, width), background_color)
        result.paste(pil_img, (0, (width - height) // 2))
        return result
    else:
        result = Image.new(pil_img.mode, (height, height), background_color)
        result.paste(pil_img, ((height - width) // 2, 0))
        return result

# âœ… 4ï¸âƒ£ `extract_image_features()` - `mm_projector` ì ìš© ì—†ì´ ì €ì¥
def extract_image_features(image_paths):
    image_tensors = []
    for image_path in image_paths:
        image = Image.open(image_path).convert("RGB")  # âœ… 1ï¸âƒ£ ì´ë¯¸ì§€ ë¡œë“œ

        # âœ… 2ï¸âƒ£ ì •í™•í•œ `expand2square()` ì ìš© (load_images() ë°©ì‹ê³¼ ë™ì¼)
        background_color = [int(c * 255) for c in image_processor.image_mean]  
        image = expand2square(image, tuple(background_color))

        # âœ… 3ï¸âƒ£ ì •í™•í•œ `image_processor.preprocess()` ì‚¬ìš© (load_images()ì™€ ë™ì¼)
        inputs = image_processor.preprocess(image, return_tensors="pt")["pixel_values"].squeeze(0).to(device)

        image_tensors.append(inputs)

    image_tensors = torch.stack(image_tensors, dim=0)  # âœ… 4ï¸âƒ£ (M, 3, 336, 336) í˜•íƒœë¡œ ë³€í™˜

    # âœ… 5ï¸âƒ£ CustomCLIPVisionEncoder ì‹¤í–‰ (CLIP Vision Model Feature ì¶”ì¶œ)
    with torch.no_grad():
        image_features = vision_tower(image_tensors)  # âœ… `mm_projector` ì ìš© ì—†ì´ ì €ì¥

    return image_features  # âœ… `1024` ì°¨ì› Feature ì €ì¥

# âœ… 5ï¸âƒ£ ì €ì¥í•  ë°ì´í„°
image_paths = ["images/0.png", "images/1.png"]
import pdb;pdb.set_trace()
image_features = extract_image_features(image_paths).cpu()
torch.save(image_features, "new_image_features.pt")  # âœ… 1024ì°¨ì› Feature ì €ì¥

print("âœ… Feature ì €ì¥ ì™„ë£Œ! ì €ì¥ í¬ê¸° ìµœì í™”ë¨ ğŸš€")
