import torch
from PIL import Image
from transformers import CLIPProcessor, T5Tokenizer
from t2v_metrics.models.vqascore_models.clip_t5_model import CLIPT5Model

# âœ… 1ï¸âƒ£ CLIPT5Model ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
vqa_model = CLIPT5Model(model_name='clip-flant5-xxl', device=device)

# âœ… 2ï¸âƒ£ CLIP Processor ë¡œë“œ (ì´ë¯¸ì§€ ì „ì²˜ë¦¬ìš©)
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14-336")

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-xxl")

# âœ… 3ï¸âƒ£ `encode_images()`ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ Feature ì¶”ì¶œ
def extract_image_features(image_paths):
    image_tensors = []
    for image_path in image_paths:
        image = Image.open(image_path).convert("RGB")
        inputs = clip_processor(images=image, return_tensors="pt")["pixel_values"].to(device)  # âœ… ì´ë¯¸ì§€ í…ì„œ ë³€í™˜
        image_tensors.append(inputs)

    # âœ… `encode_images()` ì§ì ‘ í˜¸ì¶œ
    image_tensors = torch.cat(image_tensors, dim=0)  # (M, 3, 336, 336)
    image_tensors = image_tensors.to(dtype=torch.bfloat16)  # âœ… BFloat16 ë³€í™˜ ì¶”ê°€!
    image_features = vqa_model.model.encode_images(image_tensors)  # âœ… encode_images() í˜¸ì¶œ
    return image_features  # âœ… (M, 576, 4096)

# âœ… 3ï¸âƒ£ í…ìŠ¤íŠ¸ í† í°í™” í•¨ìˆ˜
def tokenize_texts(texts):
    tokenized_texts = [tokenizer(text, return_tensors="pt")["input_ids"] for text in texts]
    tokenized_texts = torch.nn.utils.rnn.pad_sequence(
        tokenized_texts, batch_first=True, padding_value=tokenizer.pad_token_id
    )
    return tokenized_texts  # (N, sequence_length)

# âœ… 4ï¸âƒ£ ì €ì¥í•  ë°ì´í„°
image_paths = ["images/0.png", "images/1.png"]  # 2ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
texts = ["someone talks on the phone angrily while another person sits happily",
         "someone talks on the phone happily while another person sits angrily"]  # 2ê°œì˜ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸

# âœ… 5ï¸âƒ£ feature ì¶”ì¶œ ë° ì €ì¥
image_features = extract_image_features(image_paths).to("cpu")  # âœ… GPU ë©”ëª¨ë¦¬ ì ˆì•½ ìœ„í•´ CPUë¡œ ì €ì¥
torch.save(image_features, "image_features.pt")  # âœ… shape: (M, 576, 4096)

text_tokens = tokenize_texts(texts).to("cpu")
torch.save(text_tokens, "text_tokens.pt")  # âœ… shape: (N, sequence_length)

print("âœ… Feature ì €ì¥ ì™„ë£Œ! ì´ì œ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ë©° ì‹¤í–‰ ê°€ëŠ¥ ğŸš€")

